---
title: "Instrumental Variables - Assignment 9"
author: "Hilal Sankari"
format: 
    html:
      code-line-numbers: true
      df-print: paged

---
```{r}
# Load necessary libraries
library(tidyverse)
library(dagitty)
library(ggdag)
library(estimatr)
library(AER)
```
# **Part1**
#### **Define the DAG **
```{r}
dag <- dagify(
  appTime ~ newFeatureUsed,
  appTime ~ Unobserved,
  newFeatureUsed ~ Unobserved,
  newFeatureUsed ~ userEncouragement,
  exposure = "newFeatureUsed",
  latent = "Unobserved",
  outcome = "appTime",
  coords = list(x = c(Unobserved = 1, newFeatureUsed = 0, appTime = 2, userEncouragement = -1),
                y = c(Unobserved = 1, newFeatureUsed = 0, appTime = 0, userEncouragement = 0)),
  labels = c(
    "appTime" = "Time Spent on the App",
    "newFeatureUsed" = "The new feature is used",
    "userEncouragement" = "User encouragement to use feature",
    "Unobserved" = "Unobserved variables"
  )
)
```
#### **Plot DAG **
```{r}
ggdag(dag, text = FALSE, use_labels = "label")
```
# **Part2**
#### **Load the Data **
```{r}
appData <- readRDS("C:/Users/user/Documents/TUHH/Causal/Causal_Data_Science_Data/rand_enc.rds")
```
#### **Be familiar with the data **
```{r}
head(appData)
```
#### **Compute Naive Estimate **
```{r}
naiveEstimate <- lm(time_spent ~ used_ftr , data = appData)
summary(naiveEstimate)
```
# **Part3**
#### **Check the correlation matrix**
```{r}
correlationMatrix <- cor(appData) %>% round(2)
```
::: {.callout-important appearance="minimal"}
There is an upward bias in the naive estimate (10.82269) as it surpasses the IV robust estimate (9.738175) when utilizing rand_enc as an instrument. This implies that the effect of used_ftr on time_spent has been overestimated. It is clear that used_ftr and time_spent have a strong correlation. Given that rand_enc shows a weak correlation with time_spent and a higher correlation with treatment (used_ftr), it makes sense to regard it as an instrumental variable. The instrumental variable and outcome have a reasonably low correlation, even though it is not 0 (maybe because of noise).
:::
# **Part4**
#### **Instrumental Variable Estimation using 2SLS with rand_enc and robust standard errors**
```{r}
ivModelRobust <- iv_robust(time_spent ~ used_ftr  | rand_enc, data = appData)
summary(ivModelRobust)
```
#### **Hansen J test**

#### **Extract residuals and fitted values from the model**
```{r}
residualsIV <- residuals(ivModelRobust)
fittedValuesIV <- fitted(ivModelRobust)
```
#### **Perform Hansen J test**
```{r}
hansenTestStat <- sum(residualsIV * fittedValuesIV)
pValueHansen <- 1 - pchisq(hansenTestStat, df = 1)
```
#### **Display results**
```{r}
#| code-fold: true
cat("Hansen J Test Statistic:", hansenTestStat, "\n")
cat("P-value:", pValueHansen, "\n")
```
::: {.callout-important appearance="minimal"}
A Hansen J test with a test statistic near 0 and a p-value near 1 suggests that the model's instrument is not violating the over-identifying constraints. In other words, there is no evidence to suggest that the instrument is endogenous or linked with the error term, and the instrument is valid for the model.
:::
```{r}
#| code-fold: true
cat("Naive Estimate:", coef(naiveEstimate)['used_ftr'], "\n")
cat("IV Robust Estimate (rand_enc):", ivModelRobust$coefficients['used_ftr'], "\n")
```
::: {.callout-important appearance="minimal"}
We would consider the naive estimate to have an upward bias because it is larger than the IV robust estimate using rand_enc as an instrument (9.738175). This suggests that the effect of usedFeature on appTime is overestimated by the naive estimate.
:::
